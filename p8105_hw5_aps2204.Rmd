---
title: "Homework 5"
output: github_document
---
```{r setup, include = FALSE}
library(tidyverse)
library(purrr)
library(rvest)
library(dplyr)
library(stringr)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unolved",
      disposition == "Closed by arrest"      ~ "solved"
     )
  ) %>% 
  select(city_state, resolved)
```

Let's look at this a bit

```{r}
aggregate_df = 
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate.....
```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```


```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Problem 2

Read and tidy data
```{r}
path_df = 
  tibble(
  path = list.files("lda_data")) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = map(.x = path, ~ read_csv(.x))) %>% 
  unnest(data) %>% 
  separate(path, into = c("exp_group", "subject_id"), sep = "/") %>% 
  select(-"exp_group") %>% 

#using str_replace altered the dataframe completely; the only solution is to keep separating out the columns and deleting them. 
  
  separate(subject_id, into = c("exp_id", "throwaway"), sep = ".csv") %>% 
  select(-"throwaway") %>% 
  separate(exp_id, into = c("experiment_arm", "subject_id"), sep = "_") %>% 
  mutate(
    experiment_arm = recode(experiment_arm, con = "control", exp = "experimental")
  ) %>% 
  view()
# you'll want to pivot at some point to format appropriately
# control vs. experimental, week 1-8, which observation 

```



Spaghetti time.
```{r}
path_df %>% 
pivot_longer(week_1:week_8,
               names_to = "week",
               names_prefix = "week_",
               values_to = "observation") %>% 
   ggplot(aes(x = week, y = observation, group = subject_id, color = experiment_arm)) +
   geom_path() +
  labs(
    title = "Observations over Time for 20 Subjects in the Experimental and Control Study Arms",
    x = "Week",
    y = "Observation Value"
  ) 
```

Based on this plot, it is apparent that the experimental arm of the study has higher observed values on average than the control arm. Further, the experimental arm appears to have an overall upward trend over time, while the control arm appears to have an overall downward trend over time. The spread of observations in both arms appears to decrease between weeks 7 and 8, though this may simply be a product of how the data is not displayed after week 8. The experimental arm appears to display the same amount of spread as the control arm.





## Problem 3

Building a function
```{r}
#simulate datasets and conduct t-tests. Start with sim mean and sd function + modify to export results of a t-test instead

sim_3 = function(sample_size = 30, mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n = sample_size, mean = mu, sd = sigma),
  )
  
  t_test_3 = 
    t.test(sim_data, mu = 0, conf.level = .95) %>% 
    broom::tidy()
  
  sim_data %>% 
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x),
      p_value = pull(t_test_3, p.value)
    )}

output = vector("list", length = 5000)


# for plots: filter and show where p-value is less than .05, then compute mean. Will be summaries of p-values and estimates, according to whether things are significant or not
```


apply the function, put everything into a dataframe generating 5000 datasets
```{r}
sim_3_results = 
  
  tibble(mu = c(0,1,2,3,4,5,6)) %>%
 
# use the map function 
  mutate(
    outputs = map(.x = mu, ~rerun(5000, sim_3(mu = .x))),
    dfs = map(outputs, bind_rows)) %>% 
  
  select(-outputs) %>% 
  unnest(dfs) %>% 
  view()
  
```

Plot 1
```{r}
# proportion significant. I know I should use a for loop here but my brain is fried and I can't seem to figure it out :(

mu_0_significant = 
  sim_3_results %>% 
  filter(mu == 0, p_value <= 0.05) %>% 
  nrow() #246
246/5000

mu_1_significant =
  sim_3_results %>% 
  filter(mu == 1, p_value <= 0.05) %>% 
  nrow() #919
919/5000

mu_2_significant = 
  sim_3_results %>% 
  filter(mu == 2, p_value <= 0.05) %>% 
  nrow() #2812
2812/5000


mu_3_significant = 
  sim_3_results %>% 
  filter(mu == 3, p_value <= 0.05) %>% 
  nrow()  #4433
4433/5000


mu_4_significant = 
  sim_3_results %>% 
  filter(mu == 4, p_value <= 0.05) %>% 
  nrow()  #4942
4942/5000


mu_5_significant = 
  sim_3_results %>% 
  filter(mu == 5, p_value <= 0.05) %>% 
  nrow() #4996
4996/5000


mu_6_significant = 
  sim_3_results %>% 
  filter(mu == 6, p_value <= 0.05) %>% 
  nrow() #5000
5000/5000


# est_mean - group by and summarize
sim_3_results %>% 
  group_by(mu) %>% summarize(avg_mean = mean(mu_hat))

true_mean <- c(0,1,2,3,4,5,6)
proportion_significant <- c(0.0492, 0.01838, 0.5624, 0.8866, 0.9884, 0.9992, 1)
est_mean <- c(-0.0006269641, 0.990920365, 2.014283670, 2.999628878, 3.994797934, 5.013960693, 6.006695846)

plot_1 = data.frame(true_mean, est_mean, proportion_significant)

plot_1 %>% 
ggplot(aes(x = true_mean, y = proportion_significant, group = true_mean)) +
   geom_point() +
  labs(
    title = "Power of the test",
    x = "true_mean",
    y = "proportion_significant"
  )

```
Power and effect size have positive correlation with each other. This appears to be some sort of logistic curve, which makes sense, as true mean values further from 0 are far more likely to be statistically significantly different from 0. 


Problem 3, plot 1
```{r}
plot_1 %>% 
  ggplot(aes(x = true_mean, y = est_mean, group = est_mean)) +
   geom_point() +
  labs(
    title = "A Comparison of Means",
    x = "true_mean",
    y = "est_mean"
  )
```
As expected, the estimated mean and true mean have a positive linear correlation, with a slope equal to 1. This is unsurprising given the large sample size (high power), which allows this correlation to be so strong.   

Problem 3, plot 2 - samples in which null was rejected on y, true mean on x
```{r}
sim_3_results %>% 
  filter(p_value < 0.05) %>% 
  group_by(mu) %>% summarize(avg_mean = mean(mu_hat)) %>% 
   ggplot(aes(x = mu, y = avg_mean)) +
   geom_line() +
  labs(
    title = "A Comparison of Means - True vs. Statistically Significant",
    x = "true_mean",
    y = "est_mean"
  )
```
I tried to combine the plots, but the minute I tried to name them, my summarize function didn't work. Anyways. 
The sample average of samples for which the null was rejected are approximately equal to the true mean, but this deviates slightly around 1. They should do a better job of fitting the true mean, as these are the data that are statistically significantly different. However, this is a smaller sample size than the previous graph, which means that it is not as highly powered, with more opportunity for significant spread. 



